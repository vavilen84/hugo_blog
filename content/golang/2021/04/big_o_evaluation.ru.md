---
title: "Вычисление Big O для начинающих"
publishdate: "2021-04-11"
lastmod: "2021-04-11"
summary: "go"
categories:
- "golang"
tags:
- "algorithms"
- "Big O"
---

Источники:

- "Оценка сложности алгоритмов" https://www.youtube.com/watch?v=kwmQwGbAh28
- "Оценка сложности алгоритма" https://www.youtube.com/watch?v=ZRdOb4yR0kk&t=825s
- "Структуры данных для самых маленьких" https://habr.com/ru/post/310794/
- [wikipedia "Временная сложность алгоритма"](https://ru.wikipedia.org/wiki/%D0%92%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0)

Большое "O" (Big O) - определение сложности алгоритма (зависимость производительности от входных данных). Различают 
"временную" и "пространственную" сложности.

Временная сложность - зависимость количества элементарных операций от входных данных.

Пространственная сложность - зависимость расхода памяти от входных данных.

## Вычисление сложности: неважная сложность, упрощение

При вычислении наихудшего сценария отбрасываются более быстрые сложности. Например, если алгоритм имеет квадратичную 
и линейную сложности O(n{{< exp >}}2{{< /exp >}} + n), то линейная отбрасывается и, в результате, имеем квадратичную 
сложность O(n{{< exp >}}2{{< /exp >}}). 

Но, если, скажем, сложность будет O(n{{< exp >}}2{{< /exp >}} + B), при том, что мы не знаем B - отбросить его мы не 
можем. Соответственно, сложность будет O(n{{< exp >}}2{{< /exp >}} + B).

Если у нас есть сложность O(2{{< exp >}}n{{< /exp >}} + n{{< exp >}}100{{< /exp >}}) - то мы можем упростить до 
O(2{{< exp >}}n{{< /exp >}}), т.к. экспоненциальная сложность растет быстрее, чем степенная.

## Сложение сложностей

```
func sum(a, b []int) (res int) {
	for k := range a { // линейная зависимость
		res += a[k]
	}
	for k := range b { // линейная зависимость
		res += b[k]
	}
	return
}
```
сложностью данного алгоритма будет сложение двух линейных зависимостей: O(n + n) = O(n)

## Умножение сложностей
```
func multi(a [][]int) (res int) {
	for v := range a { // линейная зависимость
		for h := range a[v] { // линейная зависимость
			res += a[v][h]
		}
	}
	return
}
```
сложностью данного алгоритма будет умножение двух линейных зависимостей: O(n * n) = O(n{{< exp >}}2{{< /exp >}})

## Сложности

- Константная             O(1)       (очень хорошо, сложность не зависит от входных данных)
- Логарифмическая         O(log n)   (хорошо)
- Линейная                O(n)       (нормально)
- Линейно-логарифмическая O(n log n) (медленно)
- Квадратичное            O(n{{< exp >}}2{{< /exp >}})
- Кубическое              O(n{{< exp >}}3{{< /exp >}})
- Полиномиальная          O(n^{{< exp >}}2{{< /exp >}})    
- Экспоненциальная        O(2^{{< exp >}}n{{< /exp >}})    
- Факториальная           O(n!)      (очень медленно)


![](/posts/big_o_graph.png)

## Константная сложность - O(1)

```
func sum(a, b int) int {
    return a + b
}
```

данная функция всегда будет выполнять только одну операцию сложения независимо от значения a и b. Следовательно, большое
О - константное.

## Линейная сложность - O(n)

```
func findOffset(needle int, haystack []int) int {
	for k := range haystack {
		if haystack[k] == needle {
			return k
		}
	}
	return -1
}

func main() {
	needle := 0
	haystack := []int{3, 4, 5, -7, 0}
	res := findOffset(needle, haystack)
	fmt.Println(res) // вывод - 4
}
```

количество итераций цикла внутри функции findOffset линейно зависят от количества элементов в haystack:

- при длинне haystack равной 2, наибольшее возможное количество итераций будет равно 2
- при длинне haystack равной 10, наибольшее возможное количество итераций будет равно 10

и т.д.

Рассмотрим рекурсивную функцию

```
func sum(n int) int {
	if n == 1 {
		return n
	}
	return n + sum(n-1)
}
```

временная сложность так же будет линейная O(n), т.к. количество операций рекурсивного вызова будет расти пропорционально
величине n.

## Квадратичная O(n{{< exp >}}2{{< /exp >}}) и кубическая O(n{{< exp >}}3{{< /exp >}}) сложности

```
for keyA := range a {
    for keyB := range b {
        ...
    }
}
```

вложенный цикл имеет квадратичную сложность. Два вложенных цикла - кубическую:

```
for keyA := range a {
    for keyB := range b {
        for keyC := range c {
            ...
        }
    }
}
```

## Вычисление временной сложности

Предположим, алгоритм имеет два цикла и одну константную по времени операцию

```
func algo(n []int) int {
    res := 0
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    res += 1 // константное время O(1)
    return res
}
```

В результате мы имеем O(n + n + 1) = O(n).

Если добавим вложенный цикл, то сложность станет квадратичной: O(n + n + 1 + n{{< exp >}}2{{< /exp >}}) = 
O(n{{< exp >}}2{{< /exp >}})

```
func algo(n []int) int {
    res := 0
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    res += 1 // константное время O(1)
    for k := range n { // квадратичная зависимость O(n2)
		for c := range n {
			res += n[k] + n[c]
		}
	}
    return res
}
```

## Вычисление пространственной сложности

Алгоритм поиска максимума будет иметь константную O(1) пространственную сложность, так как расход памяти всегда будет
детерминирован:
```
func max(n []int) int {
	res := math.MinInt64 // константное выделение памяти в 64 бита под хранение числа
	for k := range n {
		if res < n[k] {
			res = n[k]
		}
	}
	return res
}
```

Алгоритм слияния срезов будет иметь линейную пространственную сложность O(n), т.к. для результирующего среза будет
выделен объем памяти пропорциональный размерам входных срезов:
```
func merge(a, b []int) []int {
	res := make([]int, len(a)+len(b)) // выделение памяти прямо пропорционально размеру входящих срезов
	for k := range a {
		res[k] = a[k]
	}
	for k := range b {
		res[len(a)+k] = b[k]
	}
	return res
}
```

## Другие примеры вычисления сложности

Дано: функция содержит цикл и вызов другой функции:
```
func sumSequence(n int) int {
	res := 0 // константное выделение памяти
	for i := 0; i < n; i++ { // линейная зависимость от n
		res += sum(i, i+1) // линейная зависимость от n
	}
	return res
}

func sum(a, b int) int {
	return a + b // константное время
}
```
Временная сложность - линейная O(n); пространственная сложность - константная O(1).

Давайте сравним две функции
```
func minMax(n []int) (min, max int) {
    // min, max - константное выделение памяти
	min = math.MaxInt64 
	max = math.MinInt64
	for k := range n { // линейная зависимость от n
		if n[k] < min {
			min = n[k]
		}
		if n[k] > max {
			max = n[k]
		}
	}
	return
}
```
```
func minMax(n []int) (min, max int) {
    // min, max - константное выделение памяти
	min = math.MaxInt64
	max = math.MinInt64
	for k := range n { // линейная зависимость от n
		if n[k] < min {
			min = n[k]
		}
	}
	for k := range n { // линейная зависимость от n
		if n[k] > max {
			max = n[k]
		}
	}
	return
}
```
Вторая функция будет работать медленнее, чем первая, т.к. будет лишняя итерация по n для определения максимального 
числа. Но, обе функции будут иметь линейную O(n) временную сложность и константную O(1) пространственную сложность.

Конец статьи!
