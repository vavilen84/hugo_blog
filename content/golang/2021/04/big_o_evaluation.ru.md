---
title: "Вычисление Big O для начинающих"
publishdate: "2021-04-11"
lastmod: "2021-04-11"
summary: "go"
categories:
- "golang"
tags:
- "algorithms"
- "Big O"
---

Источники:

- "Оценка сложности алгоритмов" https://www.youtube.com/watch?v=kwmQwGbAh28
- "Оценка сложности алгоритма" https://www.youtube.com/watch?v=ZRdOb4yR0kk&t=825s
- "Структуры данных для самых маленьких" https://habr.com/ru/post/310794/
- "Полный курс: оценка сложности алгоритмов. Нотация Big O" https://www.udemy.com/course/big-o-ru/ (Автор статьи настоятельно рекомендует данный курс к ознакомлению!)
- [wikipedia "Временная сложность алгоритма"](https://ru.wikipedia.org/wiki/%D0%92%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0)

Большое "O" (Big O) - определение сложности алгоритма (зависимость производительности от входных данных). Различают 
"временную" и "пространственную" сложности.

Временная сложность - зависимость количества элементарных операций от входных данных.

Пространственная сложность - зависимость расхода памяти от входных данных.

## Вычисление сложности: неважная сложность, упрощение

При вычислении наихудшего сценария отбрасываются более быстрые сложности. Например, если алгоритм имеет квадратичную 
и линейную сложности O(n{{< exp >}}2{{< /exp >}} + n), то линейная отбрасывается и, в результате, имеем квадратичную 
сложность O(n{{< exp >}}2{{< /exp >}}). 

Но, если, скажем, сложность будет O(n{{< exp >}}2{{< /exp >}} + B), при том, что мы не знаем B - отбросить его мы не 
можем. Соответственно, сложность будет O(n{{< exp >}}2{{< /exp >}} + B).

Если у нас есть сложность O(2{{< exp >}}n{{< /exp >}} + n{{< exp >}}100{{< /exp >}}) - то мы можем упростить до 
O(2{{< exp >}}n{{< /exp >}}), т.к. экспоненциальная сложность растет быстрее, чем степенная.

## Сложение сложностей

```
func sum(a, b []int) (res int) {
	for k := range a { // линейная зависимость
		res += a[k]
	}
	for k := range b { // линейная зависимость
		res += b[k]
	}
	return
}
```
сложностью данного алгоритма будет сложение двух линейных зависимостей: O(n + n) = O(n)

## Умножение сложностей
```
func multi(a [][]int) (res int) {
	for v := range a { // линейная зависимость
		for h := range a[v] { // линейная зависимость
			res += a[v][h]
		}
	}
	return
}
```
сложностью данного алгоритма будет умножение двух линейных зависимостей: O(n * n) = O(n{{< exp >}}2{{< /exp >}})

## Сложности

{{<table "table table-bordered">}}
| Сложность | Обозначение | Результативность |
|-----------|-------------|--------------|
| Константная   | O(1)   | отлично   |
| Логарифмическая   | O(log n)    | отлично   |
| Сублинейная   | O({{< html >}}&radic;{{< /html >}}n)   | отлично   |
| Линейная   | O(n)   | хорошо  |
| Линейно-логарифмическая   | O(n log n)   | приемлемо   |
| Квадратичное   | O(n{{< exp >}}2{{< /exp >}})   | плохо  |
| Кубическое   | O(n{{< exp >}}3{{< /exp >}})  | плохо   |
| Полиномиальная   | O(n^{{< exp >}}3{{< /exp >}})  | плохо   |
| Экспоненциальная   | O(2^{{< exp >}}n{{< /exp >}})   | плохо   |
| Факториальная  | O(n!)  | плохо  |
{{</table>}}

![](/posts/big_o_graph.png)

## Константная сложность - O(1)

```
func sum(a, b int) int {
    return a + b
}
```

данная функция всегда будет выполнять только одну операцию сложения независимо от значения a и b. Следовательно, большое
О - константное.

## Линейная сложность - O(n)

```
func findOffset(needle int, haystack []int) int {
	for k := range haystack {
		if haystack[k] == needle {
			return k
		}
	}
	return -1
}

func main() {
	needle := 0
	haystack := []int{3, 4, 5, -7, 0}
	res := findOffset(needle, haystack)
	fmt.Println(res) // вывод - 4
}
```

количество итераций цикла внутри функции findOffset линейно зависят от количества элементов в haystack:

- при длинне haystack равной 2, наибольшее возможное количество итераций будет равно 2
- при длинне haystack равной 10, наибольшее возможное количество итераций будет равно 10

и т.д.

Рассмотрим рекурсивную функцию

```
func sum(n int) int {
	if n == 1 {
		return n
	}
	return n + sum(n-1)
}
```

временная сложность так же будет линейная O(n), т.к. количество операций рекурсивного вызова будет расти пропорционально
величине n.

## Квадратичная O(n{{< exp >}}2{{< /exp >}}) и кубическая O(n{{< exp >}}3{{< /exp >}}) сложности

```
for keyA := range a {
    for keyB := range b {
        ...
    }
}
```

вложенный цикл имеет квадратичную сложность. Два вложенных цикла - кубическую:

```
for keyA := range a {
    for keyB := range b {
        for keyC := range c {
            ...
        }
    }
}
```

## Логарифмическая сложность

```
func iterate(a []int) (res int) {
	for {
		...
		if len(a) == 1 {
			break
		}
		a = a[len(a)/2:] // логарифмическая сложность
	}
	return
}
```
Для алгоритма, где на каждой итерации берется половина элементов - сложность будет включать O(log n)

## Вычисление временной сложности

Предположим, алгоритм имеет два цикла и одну константную по времени операцию

```
func algo(n []int) int {
    res := 0
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    res += 1 // константное время O(1)
    return res
}
```

В результате мы имеем O(n + n + 1) = O(n).

Если добавим вложенный цикл, то сложность станет квадратичной: O(n + n + 1 + n{{< exp >}}2{{< /exp >}}) = 
O(n{{< exp >}}2{{< /exp >}})

```
func algo(n []int) int {
    res := 0
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    for k := range n { // линейная зависимость O(n)
        res += n[k] 
    }
    res += 1 // константное время O(1)
    for k := range n { // квадратичная зависимость O(n2)
		for c := range n {
			res += n[k] + n[c]
		}
	}
    return res
}
```

## Вычисление пространственной сложности

Алгоритм поиска максимума будет иметь константную O(1) пространственную сложность, так как расход памяти всегда будет
детерминирован:
```
func max(n []int) int {
	res := math.MinInt64 // константное выделение памяти в 64 бита под хранение числа
	for k := range n {
		if res < n[k] {
			res = a
		}
	}
	return res
}
```

Алгоритм слияния срезов будет иметь линейную пространственную сложность O(n), т.к. для результирующего среза будет
выделен объем памяти пропорциональный размерам входных срезов:
```
func merge(a, b []int) []int {
	res := make([]int, len(a)+len(b)) // выделение памяти прямо пропорционально размеру входящих срезов
	for k := range a {
		res[k] = a[k]
	}
	for k := range b {
		res[len(a)+k] = b[k]
	}
	return res
}
```

## Другие примеры вычисления сложности

Дано: функция содержит цикл и вызов другой функции:
```
func sumSequence(n int) int {
	res := 0 // константное выделение памяти
	for i := 0; i < n; i++ { // линейная зависимость от n
		res += sum(i, i+1) // линейная зависимость от n
	}
	return res
}

func sum(a, b int) int {
	return a + b // константное время
}
```
Временная сложность - линейная O(n); пространственная сложность - константная O(1).

Давайте сравним две функции
```
func minMax(n []int) (min, max int) {
    // min, max - константное выделение памяти
	min = math.MaxInt64 
	max = math.MinInt64
	for k := range n { // линейная зависимость от n
		if n[k] < min {
			min = n[k]
		}
		if n[k] > max {
			max = n[k]
		}
	}
	return
}
```
```
func minMax(n []int) (min, max int) {
    // min, max - константное выделение памяти
	min = math.MaxInt64
	max = math.MinInt64
	for k := range n { // линейная зависимость от n
		if n[k] < min {
			min = n[k]
		}
	}
	for k := range n { // линейная зависимость от n
		if n[k] > max {
			max = n[k]
		}
	}
	return
}
```
Вторая функция будет работать медленнее, чем первая, т.к. будет лишняя итерация по n для определения максимального 
числа. Но, обе функции будут иметь линейную O(n) временную сложность и константную O(1) пространственную сложность.

Рассмотрим данные вложенные циклы
```
for i := 0; i < N; i++ {
    for j := 0; j < N; j++ {
        foo()
    }
}
```
```
for i := 0; i < N; i++ {
    for j := i; j < N; j++ {
        foo()
    }
}
```
из иллюстрации ниже мы видим, что во втором примере вложенный цикл уменьшается ровно на половину
![](/posts/big_o_nested_loops.png)
соответственно, для второго примера сложность будет O(n{{< exp >}}2{{< /exp >}}/2) или просто квадратичная O(n{{< exp >}}2{{< /exp >}})

Пример ниже не будет иметь кубическую сложность, т.к. сложность второго вложенного цикла - константа "100"
```
for i := 0; i < N; i++ {
    for j := 0; j < N; j++ {
        for c := 0; с < 100; j++ { // константа 100
            foo()
        }
    }
}
```

Пример ниже будет иметь сложность O(A*B), т.к. a и b различны
```
func foo(a, b []int) {
    for i := 0; i < a; i++ {
        for j := 0; j < b; j++ {
            ...
        }
    }
}
```

Пример ниже будет иметь сложность O(n/2) или просто O(n)
```
func foo(a []int){
    for i := 0; i < (len(a)/2); i++ {
        ...
    }
}
```

Давайте разберем следующий пример: дан массив строк, в нем надо отсортировать вначале сами строки, а, затем, и массив целиком.
```
func sortStrings(a []string) {
    for k := range a { // N 
        a[k] = sortString(a[k]) // L * log L 
    }
    sortArr(a) // L * N * log N
}
```
цикл по диапазону 'a' имеет линейную зависимость O(N) от количества элементов в срезе 'a'. Предположим, что в качестве 
алгоритма сортировки мы используем сортировку слиянием, которая имеет сложность O(L log L). Следовательно, часть нашего 
алгоритма, которая сортируем строки в массиве будет иметь сложность O(N * L log L). Если мы используем сортировку 
слиянием и для сортировки всего среза целиком, то сложность будет O(L * N log N), т.к. строки будут сравниваться 
посимвольно и, соответственно, L будет длинной строки. Итоговая сложность будет: 
O(N*L*log L + L*N*log N) = O(L*N*(log L + log N))

Конец статьи!
